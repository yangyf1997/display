# 20191016-20191031

## 机器学习算法-支持向量机算法（SVM）的学习
***
### 算法概述
* SVM法即支持向量机 (Support Vector Machine) 法, 由Vapnik等人于1995年提出, 具有相对优良的性能指标。
该方法是建立在统计学习理论基础上的机器学习方法。通过学习算法, SVM可以自动寻找出那些对分类有较好区分能力的支持向量,
由此构造出的分类器可以最大化类与类的间隔, 因而有较好的适应能力和较高的区分率。
该方法只需要由各类域的边界样本的类别来决定最后的分类结果。

* 支持向量机算法的目的在于寻找一个超平面H (d) , 该超平面可以将训练集中的数据分开, 
且与类域边界的沿垂直于该超平面方向的距离最大, 故SVM法亦被称为最大边缘 (Maximum Margin)算法。
所谓最优超平面就是要求超平面不但能将两类正确分开, 而且使分类间隔最大;使分类间隔最大实际上就是对模型推广能力的控制, 
这正是SVM的核心思想所在。

### 通俗理解
* 如下图所示，假设平面上有两类不同的图形，一个普通的SVM就是一条直线罢了，用来完美划分linearly separable的两类。
但这又不是一条普通的直线，这是无数条可以分类的直线当中最完美的，因为它恰好在两个类的中间，距离两个类的点都一样远。
而所谓的Support vector就是这些离分界线最近的『点』。如果是高维的点，SVM的分界线就是平面或者超平面。

![KovS41.jpg](https://s2.ax1x.com/2019/10/31/KovS41.jpg)
***
### SVM-线性可分
* 如下图，H就是决策边界，H1、H2是平行于H且过离H最近的两类样本的直线，我们将H1到H2之间的距离成为“街宽”，我们希望“街宽”越宽越好。
当给定了样本点后，如何找出决策边界使得间隔最大呢？我们定义和决策边界垂直的向量w，现在有一个样本向量u。
决策规则(Decision Rule)：如果这个u在w的投影大于一个值，就是正样本，反之负样本。（公式1），这是对于所有样本而言。

![KoqCIP.png](https://s2.ax1x.com/2019/10/31/KoqCIP.png)

* 在训练集中，需要正样本离街的距离大于等于1,反之亦然（最大间隔假设），伸缩W就可以让间隔无限大，
这里为了计算方便令距离大于等于1（公式2）。

![KoqpVI.png](https://s2.ax1x.com/2019/10/31/KoqpVI.png)

* 对于训练样本，标签都是已知的，正样本标签为1，负样本标签为-1，现在做一个转换，对公式2两边同时乘以标签yi,
我们就可以将两个式子合并为一个公式（公式3），在训练集中所有样本都需要满足这个公式。

![KobzqA.png](https://s2.ax1x.com/2019/10/31/KobzqA.png)

* 街宽就等于X+和X-的差在w上的投影（距离的定义是在单位向量上的投影），同时对于街边的点要求Yi（wx+b）=1，
对公式进行整理可以得到我们的优化目标（公式4）。

![Koq9at.png](https://s2.ax1x.com/2019/10/31/Koq9at.png)

![KoqiPf.png](https://s2.ax1x.com/2019/10/31/KoqiPf.png)

* 我们的目标是街宽最大，同时在街边的点满足等号。要求等于1，街边的点也就是所谓的支持向量的候选集，因此我们的问题可以转化为下式：
求出了优化的目标：t因此我们的优化目标就是：

![KoqkRS.png](https://s2.ax1x.com/2019/10/31/KoqkRS.png)

* 这是带约束的最小值问题，很自然我们想到了拉格朗日乘子法，我们可以写出下面的表达式，分别对w和b求偏导，令其等于0，
可以看到w是街边x的线性组合。这里只需要等式约束。

![KoqAxg.png](https://s2.ax1x.com/2019/10/31/KoqAxg.png)

* 再将对w和b求偏导的结果带入L中，可以看到L只取决于训练样本中两个向量之间两两的点乘。
其中α是拉格朗日乘子，如果我们求得了α，我们就知道了w.

![KoqVMQ.png](https://s2.ax1x.com/2019/10/31/KoqVMQ.png)

* 上式中朗格朗日乘子只有很少的一部分部位0，不等于0的乘子所对应的样本点就叫做支持向量，也就是在街边的那些点。
通过对凸优化问题（KKT、SMO）的求解就可以求得α了，w也就求出了，b也很容易求得。这时决策边界g(x)也就知道了，
我们就可以对待分类的样本进行分类了。

![KoqZrj.png](https://s2.ax1x.com/2019/10/31/KoqZrj.png)


